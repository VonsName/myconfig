input {  
    # 从终端输入  
    stdin{}  
}
input {
     file {  
        path => ["D:/logstash-6.3.0/logstash-6.3.0/logs/*.log"] ## 读取文件的路径，可以一次读取多个文件，也可以写多个file读取多个文件  
        type => "blog_test" ## 添加type字段  
        start_position => "beginning" ## 读取文件记录的开始位置
	sincedb_path => "/dev/null" #从头读  
	codec => multiline {  
		pattern => "^\<"  ##匹配每行的开头  
		negate => true    ## 是否开启正则匹配  
		what => "previous" ##未匹配的内容向前合并 如果为next，则向后合并  
	} 
    }
    filter {  
	grok {  
		match => ["message", "%{HTTPDATE:logdate}"] ##匹配日志中的时间  
	    }  
  
	date {  
	    match => [ "logdate", "yyyy-MM-dd HH:mm:ss,SSS" ] ##转换格式  
	    locale => "cn" ##确定本地时区  
	    target => "@timestamp" ##重写到@timestamp字段  
	}  
    }
}
input {  
    stdin {  
        add_field => {"field_key" => "field_value"} ## 添加若干字段  
        codec => "plain" ## 输出格式   ##codec => "json" ## 以JSON格式读取日志
        tags => ["add"] ## 添加tags  
        type => "std" ## 添加类型字段  
    }  
}

output{
    # 输出到elasticsearch
    elasticsearch {
			#action => "index"  ## 建立索引的动作，似乎可以省略  
            hosts  => "127.0.0.1:9200"
			index  => "elk_test" ## 索引的名称  
			#codec => "json" ## 输出的codec格式，codec插件在后面会提到  
        }
}
output {  
    file {  
        path => "D:/kibana-6.3.0-windows-x86_64/kibana-6.3.0-windows-x86_64/result.log" ## 保存文件的路径  
        #message_format => "%{message}" ## 可选项 保存的格式，默认输出所有字段，此处只输出message字段的内容  
        #gzip => true ## 可选项 是否压缩  
    }  
}
output {  
    stdout {  
        codec => rubydebug ## 输出格式，此处为调试格式，即JSON  
        #workers => 2 ##线程数，默认为系统核数  
    }
	# 保存到文件  
    file{  
        path => ["D:/kibana-6.3.0-windows-x86_64/kibana-6.3.0-windows-x86_64/test_result.log"]
    } 	
}